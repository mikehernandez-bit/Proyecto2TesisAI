# === App ===
APP_NAME="TesisAI Gen"
APP_ENV="dev"

# === GicaTesis Integration ===
# Base URL of GicaTesis API (Formats API v1)
GICATESIS_BASE_URL="http://localhost:8000/api/v1"

# Port for GicaGen (must be different from GicaTesis which uses 8000)
GICAGEN_PORT="8001"
GICAGEN_BASE_URL="http://localhost:8001"

# Timeout in seconds for GicaTesis requests
GICATESIS_TIMEOUT="8"

# Demo fallback: if true and GicaTesis is unavailable, /api/formats can use data/formats_sample.json
GICAGEN_DEMO_MODE="false"

# Strict GicaTesis mode: if true, /api/formats returns 503 instead of stale cache when GicaTesis is down
GICAGEN_STRICT_GICATESIS="false"

# === Legacy Format API (deprecated, use GICATESIS_* instead) ===
# FORMAT_API_BASE_URL="https://example.com/api"
# FORMAT_API_KEY=""

# === n8n Integration (DEPRECATED â€” use Gemini instead) ===
# n8n webhook URL. If empty, the app will generate a demo DOCX locally.
N8N_WEBHOOK_URL=""
# Shared secret for webhook authentication between GicaGen and n8n.
N8N_SHARED_SECRET=""
# If you use n8n, configure callback endpoint:
# POST http://localhost:8001/api/integrations/n8n/callback

# === AI Provider Selection ===
# Primary provider for generation: gemini | mistral
AI_PRIMARY_PROVIDER="gemini"
# If true, fallback to the other provider when primary hits quota (429)
AI_FALLBACK_ON_QUOTA="true"
# If true, in fixed mode allow contingency fallback only for transient TLS/network errors.
AI_FORCE_FALLBACK_ON_TRANSIENT="true"
# If true, run ai_result correction pass using data/correction_prompt.txt
AI_CORRECTION_ENABLED="true"
# Local estimate limits used by /api/providers/status (0 disables token quota estimate)
AI_LOCAL_RATE_LIMIT_PER_MINUTE="60"
AI_LOCAL_QUOTA_LIMIT_TOKENS_MONTH="0"

# === LLM Resilience ===
MAX_INFLIGHT_MISTRAL="3"
MAX_INFLIGHT_GEMINI="3"
MAX_INFLIGHT_OPENROUTER="1"
MAX_INFLIGHT_PER_TENANT="2"
MISTRAL_RPM="60"
GEMINI_RPM="60"
OPENROUTER_RPM="4"
RETRY_JITTER="0.3"
RETRY_CAP_SECONDS="45"
CB_FAILURES="5"
CB_WINDOW_SEC="60"
CB_OPEN_SEC="120"
CB_HALF_OPEN_MAX_TRIALS="2"
FALLBACK_CHAIN_GENERATE="mistral,provider_b,provider_c"
FALLBACK_CHAIN_CLEANUP="mistral,cheap_model,DEGRADED"
LLM_MAX_INPUT_TOKENS_GENERATE="6000"
LLM_MAX_OUTPUT_TOKENS_GENERATE="1400"
LLM_MAX_INPUT_TOKENS_CLEANUP="3500"
LLM_MAX_OUTPUT_TOKENS_CLEANUP="900"

# === Gemini AI Integration ===
# API key from Google AI Studio (https://aistudio.google.com/apikey)
GEMINI_API_KEY="AIzaSyAeJCZA-NdD_dWqDgWf1vYxcBgzLxnJNYs"
# Model to use for content generation
GEMINI_MODEL="gemini-2.0-flash"
# Generation parameters
GEMINI_TEMPERATURE="0.7"
GEMINI_MAX_OUTPUT_TOKENS="8192"
GEMINI_TOP_P="0.95"
# Retry configuration for API errors / rate limits
GEMINI_RETRY_MAX="3"
GEMINI_RETRY_BACKOFF="2.0"

# === Mistral AI Integration ===
# API key from Mistral Console (https://admin.mistral.ai/organization/api-keys)
MISTRAL_API_KEY="HbqtozrXLlTEzkks2N4tmUdTbMinCCvb"
MISTRAL_BASE_URL="https://api.mistral.ai/v1"
MISTRAL_MODEL="mistral-medium-2505"
MISTRAL_TEMPERATURE="0.7"
MISTRAL_MAX_TOKENS="4096"
MISTRAL_RETRY_MAX="2"
MISTRAL_RETRY_BACKOFF="2.0"

# === OpenRouter Integration ===
# API key from OpenRouter (https://openrouter.ai)
OPENROUTER_API_KEY="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"
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"
OPENROUTER_MODEL="openai/gpt-oss-120b:free"
OPENROUTER_APP_TITLE="GicaGen Tesis"
OPENROUTER_HTTP_REFERER="http://localhost:8001"
OPENROUTER_TIMEOUT_SECONDS="30"
